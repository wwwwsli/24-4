import feedparser
import streamlit as st
from datetime import datetime
import time

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¸ªæ€§åŒ–ä¿¡æ¯æ€»ç»“åŠ©æ‰‹",
    page_icon="ğŸ“š",
    layout="wide"
)

# æ ‡é¢˜
st.title("ğŸ“š ä¸ªæ€§åŒ–ä¿¡æ¯æ€»ç»“åŠ©æ‰‹")
st.markdown("---")

# ArXiv RSS æºé…ç½®
ARXIV_RSS_URL = "http://export.arxiv.org/rss/cs.AI"  # AI é¢†åŸŸçš„ RSS
KEYWORDS = ["Artificial Intelligence", "Machine Learning", "Deep Learning"]

# Mock LLM API è°ƒç”¨å‡½æ•°
def summarize_text(text):
    """
    è°ƒç”¨ LLM API è¿›è¡Œæ–‡æœ¬æ€»ç»“ï¼ˆç›®å‰ä½¿ç”¨ Mock æ•°æ®ï¼‰

    Args:
        text (str): éœ€è¦æ€»ç»“çš„æ–‡æœ¬

    Returns:
        str: æ€»ç»“åçš„æ–‡æœ¬
    """
    # è¿™é‡Œæ˜¯ Mock æ•°æ®ï¼Œå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºçœŸå®çš„ API è°ƒç”¨
    mock_summary = f"""
    [AI æ€»ç»“] æœ¬æ–‡ä¸»è¦ç ”ç©¶äº†äººå·¥æ™ºèƒ½é¢†åŸŸçš„å‰æ²¿è¿›å±•ã€‚è®ºæ–‡æå‡ºäº†åˆ›æ–°æ€§çš„æ–¹æ³•ï¼Œ
    åœ¨ç›¸å…³ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å…·æœ‰å¾ˆå¥½çš„
    åº”ç”¨å‰æ™¯å’Œå®ç”¨ä»·å€¼ã€‚ä½œè€…é€šè¿‡å……åˆ†çš„å®éªŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œä¸ºè¯¥é¢†åŸŸ
    çš„å‘å±•åšå‡ºäº†é‡è¦è´¡çŒ®ã€‚
    """
    return mock_summary.strip()

def fetch_arxiv_papers():
    """
    æŠ“å– ArXiv çš„ RSS è®¢é˜…æº

    Returns:
        list: è®ºæ–‡åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«æ ‡é¢˜ã€ä½œè€…ã€æ‘˜è¦ã€å‘å¸ƒæ—¥æœŸç­‰ä¿¡æ¯
    """
    try:
        # è§£æ RSS æº
        feed = feedparser.parse(ARXIV_RSS_URL)

        papers = []

        for entry in feed.entries:
            paper = {
                'title': entry.title,
                'authors': [author.name for author in entry.authors] if hasattr(entry, 'authors') else [],
                'summary': entry.summary,
                'published_date': entry.published,
                'link': entry.link,
                'categories': entry.tags if hasattr(entry, 'tags') else []
            }
            papers.append(paper)

        return papers

    except Exception as e:
        st.error(f"æŠ“å– ArXiv è®ºæ–‡æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return []

def display_paper(paper):
    """
    æ˜¾ç¤ºå•ç¯‡è®ºæ–‡çš„ä¿¡æ¯

    Args:
        paper (dict): è®ºæ–‡ä¿¡æ¯å­—å…¸
    """
    with st.expander(f"**{paper['title'][:100]}{'...' if len(paper['title']) > 100 else ''}**"):
        # æ ‡é¢˜
        st.markdown(f"### ğŸ“– {paper['title']}")

        # ä½œè€…å’Œæ—¥æœŸ
        authors_str = ", ".join(paper['authors'][:3])  # åªæ˜¾ç¤ºå‰3ä½ä½œè€…
        if len(paper['authors']) > 3:
            authors_str += f" ç­‰ ({len(paper['authors'])} ä½ä½œè€…)"

        col1, col2 = st.columns([3, 1])
        with col1:
            st.markdown(f"**ğŸ‘¤ ä½œè€…**: {authors_str}")
        with col2:
            if paper['published_date']:
                try:
                    pub_date = datetime.strptime(paper['published_date'], '%a, %d %b %Y %H:%M:%S %Z')
                    st.markdown(f"**ğŸ“… å‘å¸ƒ**: {pub_date.strftime('%Y-%m-%d')}")
                except:
                    st.markdown(f"**ğŸ“… å‘å¸ƒ**: {paper['published_date'][:10]}")

        # é“¾æ¥
        st.markdown(f"**ğŸ”— [åŸæ–‡é“¾æ¥]({paper['link']})**")

        # æ‘˜è¦
        st.markdown("#### ğŸ“„ æ‘˜è¦")
        st.write(paper['summary'])

        # AI æ€»ç»“
        st.markdown("#### ğŸ¤– AI æ€»ç»“")
        with st.spinner("æ­£åœ¨ç”Ÿæˆæ€»ç»“..."):
            time.sleep(1)  # æ¨¡æ‹Ÿ API è°ƒç”¨å»¶è¿Ÿ
            summary = summarize_text(paper['summary'])
            st.write(summary)

# ä¸»ç•Œé¢
def main():
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")

        # æ˜¾ç¤ºæŠ“å–çš„è®ºæ–‡æ•°é‡
        st.subheader("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
        st.metric("å…³é”®è¯", ", ".join(KEYWORDS))
        st.metric("RSS æº", ARXIV_RSS_URL)

        # åˆ·æ–°æŒ‰é’®
        if st.button("ğŸ”„ åˆ·æ–°è®ºæ–‡", type="primary"):
            st.rerun()

    # ä¸»ä½“å†…å®¹
    st.header("ğŸ“‹ æœ€æ–° AI è®ºæ–‡")

    # æ˜¾ç¤ºåŠ è½½çŠ¶æ€
    with st.spinner("æ­£åœ¨æŠ“å– ArXiv æœ€æ–°è®ºæ–‡..."):
        papers = fetch_arxiv_papers()

    # æ˜¾ç¤ºè®ºæ–‡æ•°é‡
    st.info(f"æ‰¾åˆ° {len(papers)} ç¯‡ç›¸å…³è®ºæ–‡")

    # æ˜¾ç¤ºè®ºæ–‡åˆ—è¡¨
    if papers:
        # æœç´¢æ¡†
        search_term = st.text_input("ğŸ” æœç´¢è®ºæ–‡æ ‡é¢˜æˆ–æ‘˜è¦", "")

        # è¿‡æ»¤è®ºæ–‡
        filtered_papers = papers
        if search_term:
            filtered_papers = [
                paper for paper in papers
                if search_term.lower() in paper['title'].lower() or
                   search_term.lower() in paper['summary'].lower()
            ]
            st.info(f"æ‰¾åˆ° {len(filtered_papers)} ç¯‡åŒ¹é…çš„è®ºæ–‡")

        # æ˜¾ç¤ºè®ºæ–‡
        for paper in filtered_papers:
            display_paper(paper)
    else:
        st.warning("æœªèƒ½è·å–åˆ°è®ºæ–‡æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚")

# è¿è¡Œåº”ç”¨
if __name__ == "__main__":
    main()